{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZBCZsrt58h3"
      },
      "source": [
        "Use basic Fully connected network to compare the different activation functions on adversarial robustness and accuracy. +-2hours to run with 10 loops\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9Jk0IRymHsK"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet foolbox\n",
        "!pip install --quiet scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XaaFSb9KVD1F"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.optim as optim\n",
        "import foolbox as fb\n",
        "import eagerpy as ep\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datetime import datetime\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZcexZBLC5bm"
      },
      "outputs": [],
      "source": [
        "# Constants\n",
        "dimension = 2 # dimension of dataset\n",
        "noise = False # add noise to the dataset\n",
        "dataset_type = 'square' # 'circle' or 'square'\n",
        "num_points = 3200 # number of points in the dataset\n",
        "num_epochs = 1000 # maximum number of epochs before training is stopped\n",
        "number_of_loops = 10 # number of times that each experiment is repeated\n",
        "batch_size = 32\n",
        "max_epsilon = 1.2\n",
        "number_of_epsilons = int(max_epsilon * 40) # number of different attack values that are tested\n",
        "epsilons = np.linspace(0.0, max_epsilon, number_of_epsilons) # relative attack values\n",
        "learning_rate = 0.001 # learning rate for training\n",
        "weight_decay = 1e-5 # weight decay for training\n",
        "margin = 0.0013232710934127376 # margin for hinge loss\n",
        "\n",
        "\n",
        "# Models\n",
        "model_names = [\n",
        "    'ReLU', 'Leaky ReLU', 'Softplus',\n",
        "    'Leaky Softplus', 'Semi-Leaky Softplus','Tanh',\n",
        "    'Leaky Tanh', 'Sigmoid', 'Leaky Sigmoid'\n",
        "]\n",
        "\n",
        "# Corresponding colors for each model\n",
        "colors = [\n",
        "    'blue', 'lightblue', 'darkorange', 'orange', 'gold', 'green',\n",
        "    'lightgreen', 'red', 'pink'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mBMqJaRLVPuj"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qq2RCgaJXt_K"
      },
      "outputs": [],
      "source": [
        "# Define activation functions\n",
        "\n",
        "def LeakyReLU(x,left_slope=0.01,right_slope=1):\n",
        "  return torch.max(left_slope*x, right_slope*x)\n",
        "\n",
        "def ReLU(x):\n",
        "  return LeakyReLU(x,0)\n",
        "\n",
        "def Softplus(x):\n",
        "  return torch.log(1+torch.exp(x))\n",
        "\n",
        "def LeakySoftplus(x):\n",
        "  return 0.01*x+ torch.log(1+torch.exp(x)) - 0.693147207\n",
        "\n",
        "def SemiLeakySoftplus(x):\n",
        "  return torch.where(x < 0, 0.01 * x + torch.log(1 + torch.exp(x)), torch.log(1 + torch.exp(x))) - 0.693147207\n",
        "\n",
        "def Tanh(x):\n",
        "  return torch.tanh(x)\n",
        "\n",
        "def LeakyTanh(x):\n",
        "  return 0.01*x + Tanh(x)\n",
        "\n",
        "def Sigmoid(x):\n",
        "  return 1/(1+torch.exp(-x))\n",
        "\n",
        "def LeakySigmoid(x):\n",
        "  return 0.01*x + Sigmoid(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHspPPbvngJc"
      },
      "outputs": [],
      "source": [
        "# Utils --> from the paper 'Dynamical Systems'\n",
        "\n",
        "def sumOne(u):\n",
        "  u = Positive(u)\n",
        "  u = u/torch.sum(u)\n",
        "  return Positive(u)\n",
        "\n",
        "def Positive(X):\n",
        "    return torch.abs(X)\n",
        "\n",
        "# From https://github.com/JiJingYu/delta_orthogonal_init_pytorch/blob/master/demo.py\n",
        "def genOrthgonal(dim):\n",
        "    a = torch.zeros((dim, dim)).normal_(0, 1)\n",
        "    q, r = torch.linalg.qr(a)\n",
        "    d = torch.diag(r, 0).sign()\n",
        "    diag_size = d.size(0)\n",
        "    d_exp = d.view(1, diag_size).expand(diag_size, diag_size)\n",
        "    q.mul_(d_exp)\n",
        "    return q\n",
        "\n",
        "def makeDeltaOrthogonal(weights, gain):\n",
        "    rows = weights.size(0)\n",
        "    cols = weights.size(1)\n",
        "    if rows > cols:\n",
        "        print(\"In_filters should not be greater than out_filters.\")\n",
        "    weights.data.fill_(0)\n",
        "    dim = max(rows, cols)\n",
        "    q = genOrthgonal(dim)\n",
        "    mid1 = weights.size(2) // 2\n",
        "    mid2 = weights.size(3) // 2\n",
        "    weights[:, :, mid1, mid2] = q[:weights.size(0), :weights.size(1)]\n",
        "    weights.mul_(gain)\n",
        "\n",
        "#Convolutional layers\n",
        "def deconv_orth_dist(kernel, padding = 2, stride = 1):\n",
        "    [o_c, i_c, w, h] = kernel.shape\n",
        "    output = torch.conv2d(kernel, kernel, padding=padding)\n",
        "    target = torch.zeros((o_c, o_c, output.shape[-2], output.shape[-1])).to(kernel.device)\n",
        "    ct = int(np.floor(output.shape[-1]/2))\n",
        "    target[:,:,ct,ct] = torch.eye(o_c).to(kernel.device)\n",
        "    return torch.norm( output - target )\n",
        "\n",
        "def conv_orth_dist(kernel, stride = 1):\n",
        "    [o_c, i_c, w, h] = kernel.shape\n",
        "    assert (w == h),\"Do not support rectangular kernel\"\n",
        "    assert stride<w,\"Please use matrix orthgonality instead\"\n",
        "    new_s = stride*(w-1) + w#np.int(2*(half+np.floor(half/stride))+1)\n",
        "    temp = torch.eye(new_s*new_s*i_c).reshape((new_s*new_s*i_c, i_c, new_s,new_s)).to(kernel.device)\n",
        "    out = (F.conv2d(temp, kernel, stride=stride)).reshape((new_s*new_s*i_c, -1))\n",
        "    Vmat = out[np.floor(new_s**2/2).astype(int)::new_s**2, :]\n",
        "    temp= np.zeros((i_c, i_c*new_s**2))\n",
        "    for i in range(temp.shape[0]):temp[i,np.floor(new_s**2/2).astype(int)+new_s**2*i]=1\n",
        "    return torch.norm( Vmat@torch.t(out) - torch.from_numpy(temp).float().to(kernel.device) )\n",
        "\n",
        "#Fully connected layers\n",
        "def orth_dist(mat, stride=None):\n",
        "    mat = mat.reshape( (mat.shape[0], -1) )\n",
        "    if mat.shape[0] < mat.shape[1]:\n",
        "        mat = mat.permute(1,0)\n",
        "    return torch.norm( torch.t(mat)@mat - torch.eye(mat.shape[1]).to(mat.device))\n",
        "\n",
        "def power_method(A, A_t, u_init, k=1):\n",
        "    u = u_init\n",
        "    for i in range(k):\n",
        "        v = A(u)\n",
        "        v /= torch.sqrt(torch.sum(v**2))\n",
        "        u = A_t(v)\n",
        "        sigma = torch.sum(u * u)\n",
        "        u /= torch.sqrt(torch.sum(u**2))\n",
        "    return sigma, u[0] #so it returns a 3d tensor\n",
        "\n",
        "def compute_spectral_norm(conv, u_init=None, im_size=(3, 32, 32), k=1):\n",
        "    if u_init is None:\n",
        "        with torch.no_grad():\n",
        "            u_init = torch.randn(1, *im_size).to(conv.weight.device)\n",
        "    u_init = u_init.to(conv.weight.device)\n",
        "    with torch.no_grad():\n",
        "        return power_method(lambda u: torch.nn.functional.conv2d(u, conv.weight, padding=tuple(v//2 for v in conv.weight.shape[2:])),\n",
        "                lambda v: torch.nn.functional.conv_transpose2d(v, conv.weight, padding=tuple(v//2 for v in conv.weight.shape[2:])),\n",
        "                u_init, k)\n",
        "\n",
        "def conv_block(in_channels, out_channels, pool=False):\n",
        "    convo = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1,bias=False)\n",
        "    layers = [convo]\n",
        "    if pool: layers.append(nn.MaxPool2d(2))\n",
        "    return nn.Sequential(*layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNE7MzJq7ZcJ"
      },
      "outputs": [],
      "source": [
        "class multiClassHingeLoss(nn.Module): # From paper Dynamical Systems\n",
        "    def __init__(self, p=1, margin=margin, device='cpu', size_average=True):\n",
        "        super(multiClassHingeLoss, self).__init__()\n",
        "        self.margin=margin\n",
        "        self.size_average=size_average\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, output, y):\n",
        "        output_y=output[torch.arange(0,y.size()[0]).long().to(self.device),y.data.to(self.device)].view(-1,1) #it is a (Batch Size x 1) tensor, having entries that are x[y]\n",
        "        loss=output-output_y+self.margin #this has self.margin in position y and the difference between the entry of x and x[y] in the other positions\n",
        "        #remove i=y items\n",
        "        loss[torch.arange(0,y.size()[0]).long().to(self.device),y.data.to(self.device)]=0 #sets to 0 the entry in position y, instead of having self.margin\n",
        "        #max(0,_)\n",
        "        loss[loss<0]=0 #sets to 0 the entries of loss where we have negative numbers, i.e. those meeting the margin (there is a higher difference than the margin between x[y] and x[i])\n",
        "        #sum up\n",
        "        loss=torch.sum(loss)\n",
        "        if(self.size_average):\n",
        "            loss/=output.size()[0]\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dbC-Nw6Lhdi6"
      },
      "outputs": [],
      "source": [
        "# Define the models\n",
        "if dataset_type == 'circle':\n",
        "  num_outputs = 3\n",
        "elif dataset_type == 'square':\n",
        "  num_outputs = 4\n",
        "else:\n",
        "  raise ValueError(\"Invalid dataset type. Choose either 'circle' or 'square' at the top of the file.\")\n",
        "\n",
        "class SoftplusModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SoftplusModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(dimension, 31)\n",
        "        self.fc2 = nn.Linear(31, 3)\n",
        "        self.fc3 = nn.Linear(3, 8)\n",
        "        self.fc4 = nn.Linear(8, num_outputs)\n",
        "        self.name = 'Softplus'\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = Softplus(self.fc1(x))\n",
        "        x = Softplus(self.fc2(x))\n",
        "        x = Softplus(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "class LeakySoftplusModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeakySoftplusModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(dimension, 31)\n",
        "        self.fc2 = nn.Linear(31, 3)\n",
        "        self.fc3 = nn.Linear(3, 8)\n",
        "        self.fc4 = nn.Linear(8, num_outputs)\n",
        "        self.name = 'Leaky Softplus'\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = LeakySoftplus(self.fc1(x))\n",
        "        x = LeakySoftplus(self.fc2(x))\n",
        "        x = LeakySoftplus(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "class SemiLeakySoftplusModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SemiLeakySoftplusModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(dimension, 31)\n",
        "        self.fc2 = nn.Linear(31, 3)\n",
        "        self.fc3 = nn.Linear(3, 8)\n",
        "        self.fc4 = nn.Linear(8, num_outputs)\n",
        "        self.name = 'Semi-Leaky Softplus'\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = SemiLeakySoftplus(self.fc1(x))\n",
        "        x = SemiLeakySoftplus(self.fc2(x))\n",
        "        x = SemiLeakySoftplus(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "class TanhModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TanhModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(dimension, 31)\n",
        "        self.fc2 = nn.Linear(31, 3)\n",
        "        self.fc3 = nn.Linear(3, 8)\n",
        "        self.fc4 = nn.Linear(8, num_outputs)\n",
        "        self.name = 'Tanh'\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = Tanh(self.fc1(x))\n",
        "        x = Tanh(self.fc2(x))\n",
        "        x = Tanh(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "class LeakyTanhModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeakyTanhModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(dimension, 31)\n",
        "        self.fc2 = nn.Linear(31, 3)\n",
        "        self.fc3 = nn.Linear(3, 8)\n",
        "        self.fc4 = nn.Linear(8, num_outputs)\n",
        "        self.name = 'Leaky Tanh'\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = LeakyTanh(self.fc1(x))\n",
        "        x = LeakyTanh(self.fc2(x))\n",
        "        x = LeakyTanh(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class SigmoidModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SigmoidModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(dimension, 31)\n",
        "        self.fc2 = nn.Linear(31, 3)\n",
        "        self.fc3 = nn.Linear(3, 8)\n",
        "        self.fc4 = nn.Linear(8, num_outputs)\n",
        "        self.name = 'Sigmoid'\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = Sigmoid(self.fc1(x))\n",
        "        x = Sigmoid(self.fc2(x))\n",
        "        x = Sigmoid(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "class LeakySigmoidModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeakySigmoidModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(dimension, 31)\n",
        "        self.fc2 = nn.Linear(31, 3)\n",
        "        self.fc3 = nn.Linear(3, 8)\n",
        "        self.fc4 = nn.Linear(8, num_outputs)\n",
        "        self.name = 'Leaky Sigmoid'\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = LeakySigmoid(self.fc1(x))\n",
        "        x = LeakySigmoid(self.fc2(x))\n",
        "        x = LeakySigmoid(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class ReluModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ReluModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(dimension, 31)\n",
        "        self.fc2 = nn.Linear(31, 3)\n",
        "        self.fc3 = nn.Linear(3, 8)\n",
        "        self.fc4 = nn.Linear(8, num_outputs)\n",
        "        self.name = 'ReLU'\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = ReLU(self.fc1(x))\n",
        "        x = ReLU(self.fc2(x))\n",
        "        x = ReLU(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "class LeakyReluModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeakyReluModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(dimension, 31)\n",
        "        self.fc2 = nn.Linear(31, 3)\n",
        "        self.fc3 = nn.Linear(3, 8)\n",
        "        self.fc4 = nn.Linear(8, num_outputs)\n",
        "        self.name = 'Leaky ReLU'\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = LeakyReLU(self.fc1(x))\n",
        "        x = LeakyReLU(self.fc2(x))\n",
        "        x = LeakyReLU(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lc_vPSClF9Ep"
      },
      "outputs": [],
      "source": [
        "# Functions used to generate datasets\n",
        "\n",
        "def GenerateCircleDataset(noise=False, num_points=num_points):\n",
        "  # Generate random points\n",
        "  points = np.random.randn(num_points, dimension)\n",
        "\n",
        "  # Calculate distances to the origin\n",
        "  distances = np.linalg.norm(points, axis=1)\n",
        "\n",
        "  # Generate labels: 0 if distance < 2/3, 1 if 2/3 < distance < 4/3, 2 if distance > 4/3\n",
        "  labels = np.zeros_like(distances)\n",
        "  labels[distances > 2/3] = 1\n",
        "  labels[distances > 4/3] = 2\n",
        "\n",
        "  # Convert numpy arrays to PyTorch tensors\n",
        "  labels_tensor = torch.tensor(labels, dtype=torch.long)\n",
        "  if noise:\n",
        "    noise = 0.1*np.random.randn(num_points, dimension)\n",
        "    noisy_points = points + noise\n",
        "    points_tensor = torch.tensor(noisy_points, dtype=torch.float32)\n",
        "  else:\n",
        "    points_tensor = torch.tensor(points, dtype=torch.float32)\n",
        "\n",
        "  return points_tensor, labels_tensor\n",
        "\n",
        "def GenerateSquareDataset(noise=False, num_points=num_points):\n",
        "    # Generate random points uniformly between -1 and 1\n",
        "    points = np.random.uniform(low=-1.0, high=1.0, size=(num_points, dimension))\n",
        "\n",
        "    # Initialize labels\n",
        "    labels = np.zeros(num_points)\n",
        "\n",
        "    # Assign labels based on quadrant\n",
        "    for i, point in enumerate(points):\n",
        "        if point[0] >= 0 and point[1] >= 0:\n",
        "            labels[i] = 0  # Quadrant 1\n",
        "        elif point[0] < 0 and point[1] >= 0:\n",
        "            labels[i] = 1  # Quadrant 2\n",
        "        elif point[0] < 0 and point[1] < 0:\n",
        "            labels[i] = 2  # Quadrant 3\n",
        "        else:\n",
        "            labels[i] = 3  # Quadrant 4\n",
        "\n",
        "    # Convert numpy arrays to PyTorch tensors\n",
        "    labels_tensor = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    if noise:\n",
        "        # Add noise to the points\n",
        "        noise = 0.1 * np.random.randn(num_points, dimension)\n",
        "        noisy_points = points + noise\n",
        "        points_tensor = torch.tensor(noisy_points, dtype=torch.float32)\n",
        "    else:\n",
        "        points_tensor = torch.tensor(points, dtype=torch.float32)\n",
        "\n",
        "    return points_tensor, labels_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEJD7pObm9cS"
      },
      "outputs": [],
      "source": [
        "# Functions used to train and attack the models\n",
        "\n",
        "def TrainAndAttack(model, num_epochs, batch_size, number_of_loops, number_of_epsilons, points_tensor, labels_tensor, accuracy0, robust_accuracy0, patience=6):\n",
        "  # criterion = nn.CrossEntropyLoss()\n",
        "  criterion = multiClassHingeLoss()\n",
        "  optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "  # Split the data into training and validation sets\n",
        "  train_points, val_points, train_labels, val_labels = train_test_split(points_tensor, labels_tensor, test_size=0.2)\n",
        "\n",
        "  best_val_loss = float('inf')\n",
        "  epochs_without_improvement = 0\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "      model.train()\n",
        "      for i in range(0, len(train_points), batch_size):\n",
        "          inputs = train_points[i:i+batch_size]\n",
        "          targets = train_labels[i:i+batch_size]\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "          outputs = model(inputs)\n",
        "          loss = criterion(outputs, targets)\n",
        "\n",
        "          if torch.isnan(loss):\n",
        "            print(\"NaN loss detected, stopping training.\")\n",
        "            return epoch, -1\n",
        "\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "      # Validation step\n",
        "      model.eval()\n",
        "      val_loss = 0.0\n",
        "      with torch.no_grad():\n",
        "          for i in range(0, len(val_points), batch_size):\n",
        "              inputs = val_points[i:i+batch_size]\n",
        "              targets = val_labels[i:i+batch_size]\n",
        "              outputs = model(inputs)\n",
        "              loss = criterion(outputs, targets)\n",
        "              if torch.isnan(loss):\n",
        "                print(\"NaN loss detected, stopping training.\")\n",
        "                return epoch, -1\n",
        "              val_loss += loss.item()\n",
        "\n",
        "      val_loss /= len(val_points) // batch_size\n",
        "      print(f'Time: {datetime.now().strftime(\"%H:%M:%S\")}, Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}, Val Loss: {val_loss}, Model: {model.name}, Loop: {loop+1} / {number_of_loops}, Epochs without improvement:{epochs_without_improvement}')\n",
        "\n",
        "      # Check for early stopping\n",
        "      if val_loss < best_val_loss:\n",
        "          best_val_loss = val_loss\n",
        "          epochs_without_improvement = 0\n",
        "      else:\n",
        "          epochs_without_improvement += 1\n",
        "          if epochs_without_improvement >= patience:\n",
        "              print(f'Early stopping triggered after {epoch+1} epochs')\n",
        "              break\n",
        "\n",
        "  with torch.no_grad():\n",
        "      outputs = model(points_tensor)\n",
        "      _, predicted = torch.max(outputs, 1)\n",
        "      accuracy = (predicted == labels_tensor).sum().item() / num_points\n",
        "\n",
        "  accuracy0[loop] = accuracy\n",
        "  print(f'Accuracy: {accuracy}, Loop: {loop}')\n",
        "\n",
        "  model.eval()\n",
        "  fmodel = fb.PyTorchModel(model, bounds=(-30, 30), preprocessing=None)\n",
        "\n",
        "  # Create the Foolbox attack\n",
        "  attack = fb.attacks.LinfDeepFoolAttack()\n",
        "\n",
        "  # Evaluate the adversarial robustness\n",
        "  num_adversarial = 0\n",
        "  attack = fb.attacks.LinfDeepFoolAttack()\n",
        "  raw, clipped, is_adv = attack(fmodel, points_tensor, labels_tensor, epsilons=epsilons)\n",
        "  robust_accuracy0[loop] = torch.mean((1-1.*is_adv),axis=1).detach().cpu().numpy()\n",
        "\n",
        "  return epoch, 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "L23PjA8MqLfT",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Initialize arrays\n",
        "accuracy1 = np.zeros(number_of_loops)\n",
        "accuracy2 = np.zeros(number_of_loops)\n",
        "accuracy3 = np.zeros(number_of_loops)\n",
        "accuracy4 = np.zeros(number_of_loops)\n",
        "accuracy5 = np.zeros(number_of_loops)\n",
        "accuracy6 = np.zeros(number_of_loops)\n",
        "accuracy7 = np.zeros(number_of_loops)\n",
        "accuracy8 = np.zeros(number_of_loops)\n",
        "accuracy9 = np.zeros(number_of_loops)\n",
        "\n",
        "actual_epochs = np.zeros([number_of_loops, 9])\n",
        "successes = np.zeros([number_of_loops, 9])\n",
        "\n",
        "\n",
        "robust_accuracy1 = np.zeros((number_of_loops,number_of_epsilons))\n",
        "robust_accuracy2 = np.zeros((number_of_loops,number_of_epsilons))\n",
        "robust_accuracy3 = np.zeros((number_of_loops,number_of_epsilons))\n",
        "robust_accuracy4 = np.zeros((number_of_loops,number_of_epsilons))\n",
        "robust_accuracy5 = np.zeros((number_of_loops,number_of_epsilons))\n",
        "robust_accuracy6 = np.zeros((number_of_loops,number_of_epsilons))\n",
        "robust_accuracy7 = np.zeros((number_of_loops,number_of_epsilons))\n",
        "robust_accuracy8 = np.zeros((number_of_loops,number_of_epsilons))\n",
        "robust_accuracy9 = np.zeros((number_of_loops,number_of_epsilons))\n",
        "\n",
        "\n",
        "# Perform experiments\n",
        "for loop in range(number_of_loops):\n",
        "  if dataset_type == 'circle':\n",
        "    points_tensor, labels_tensor = GenerateCircleDataset(noise=noise)\n",
        "  elif dataset_type == 'square':\n",
        "    points_tensor, labels_tensor = GenerateSquareDataset(noise=noise)\n",
        "  else:\n",
        "    raise ValueError(\"Invalid dataset type. Choose either 'circle' or 'square' at the top of the file.\")\n",
        "\n",
        "  # Instantiate the models\n",
        "  model1 = ReluModel()\n",
        "  model2 = LeakyReluModel()\n",
        "  model3 = SoftplusModel()\n",
        "  model4 = LeakySoftplusModel()\n",
        "  model5 = SemiLeakySoftplusModel()\n",
        "  model6 = TanhModel()\n",
        "  model7 = LeakyTanhModel()\n",
        "  model8 = SigmoidModel()\n",
        "  model9 = LeakySigmoidModel()\n",
        "\n",
        "  # Train and attack the models\n",
        "  actual_epochs[loop, 0], successes[loop,0] = TrainAndAttack(model1, num_epochs, batch_size, number_of_loops, number_of_epsilons, points_tensor, labels_tensor, accuracy1, robust_accuracy1)\n",
        "  actual_epochs[loop, 1], successes[loop,1] = TrainAndAttack(model2, num_epochs, batch_size, number_of_loops, number_of_epsilons, points_tensor, labels_tensor, accuracy2, robust_accuracy2)\n",
        "  actual_epochs[loop, 2], successes[loop,2] = TrainAndAttack(model3, num_epochs, batch_size, number_of_loops, number_of_epsilons, points_tensor, labels_tensor, accuracy3, robust_accuracy3)\n",
        "  actual_epochs[loop, 3], successes[loop,3] = TrainAndAttack(model4, num_epochs, batch_size, number_of_loops, number_of_epsilons, points_tensor, labels_tensor, accuracy4, robust_accuracy4)\n",
        "  actual_epochs[loop, 4], successes[loop,4] = TrainAndAttack(model5, num_epochs, batch_size, number_of_loops, number_of_epsilons, points_tensor, labels_tensor, accuracy5, robust_accuracy5)\n",
        "  actual_epochs[loop, 5], successes[loop,5] = TrainAndAttack(model6, num_epochs, batch_size, number_of_loops, number_of_epsilons, points_tensor, labels_tensor, accuracy6, robust_accuracy6)\n",
        "  actual_epochs[loop, 6], successes[loop,6] = TrainAndAttack(model7, num_epochs, batch_size, number_of_loops, number_of_epsilons, points_tensor, labels_tensor, accuracy7, robust_accuracy7)\n",
        "  actual_epochs[loop, 7], successes[loop,7] = TrainAndAttack(model8, num_epochs, batch_size, number_of_loops, number_of_epsilons, points_tensor, labels_tensor, accuracy8, robust_accuracy8)\n",
        "  actual_epochs[loop, 8], successes[loop,8] = TrainAndAttack(model9, num_epochs, batch_size, number_of_loops, number_of_epsilons, points_tensor, labels_tensor, accuracy9, robust_accuracy9)\n",
        "\n",
        "  # Visualize the last dataset\n",
        "  if loop == number_of_loops-1 :\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.scatter(points_tensor[:, 0], points_tensor[:, 1], c=labels_tensor, cmap='viridis')\n",
        "    plt.colorbar(label='Labels')\n",
        "    plt.title('Dataset')\n",
        "    plt.xlabel('X')\n",
        "    plt.ylabel('Y')\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a774fzVMA0os"
      },
      "outputs": [],
      "source": [
        "# Fix dimensionality\n",
        "actual_epochs = np.transpose(actual_epochs)\n",
        "successes = np.transpose(successes)\n",
        "train_accuracies = [\n",
        "    accuracy1, accuracy2, accuracy3,\n",
        "    accuracy4, accuracy5, accuracy6,\n",
        "    accuracy7, accuracy8, accuracy9\n",
        "]\n",
        "train_accuracies = np.array(train_accuracies)\n",
        "robust_accuracies = [\n",
        "    robust_accuracy1, robust_accuracy2, robust_accuracy3,\n",
        "    robust_accuracy4, robust_accuracy5, robust_accuracy6,\n",
        "    robust_accuracy7, robust_accuracy8, robust_accuracy9\n",
        "]\n",
        "\n",
        "# Filter the accuracies to exclude failed runs\n",
        "marked_train_accuracies = np.where(successes == 0, train_accuracies, np.nan)\n",
        "average_successful_train_accuracies = np.nanmean(marked_train_accuracies, axis=1)\n",
        "\n",
        "# Filter the robust accuracies to exclude failed runs\n",
        "marked_robust_accuracies = robust_accuracies\n",
        "marked_robust_accuracies = np.array(marked_robust_accuracies)\n",
        "for j in range(number_of_loops):\n",
        "  for i in range(9):\n",
        "    if successes[i,j] == -1:\n",
        "      marked_robust_accuracies[i,j] = np.nan\n",
        "\n",
        "average_successful_robust_accuracies = np.zeros_like(average_successful_train_accuracies)\n",
        "for i in range(9):\n",
        "  average_successful_robust_accuracies[i] = np.nanmean(marked_robust_accuracies[i,:,:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmLyi9d6BbOj"
      },
      "outputs": [],
      "source": [
        "# Calculate the total number of fails per model\n",
        "fails_per_model = np.sum(successes == -1, axis=1)\n",
        "\n",
        "# Calculate the average number of required epochs per model (excluding failed ones)\n",
        "avg_epochs_per_model = np.where(successes != -1, actual_epochs, np.nan)\n",
        "avg_epochs_per_model = np.nanmean(avg_epochs_per_model, axis=1)\n",
        "\n",
        "# Plot the total number of fails per model\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(model_names, fails_per_model, color='red')\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('Total Number of Fails')\n",
        "plt.title('Total Number of Fails per Model')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.show()\n",
        "\n",
        "# Plot the average number of required epochs per model\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(model_names, avg_epochs_per_model, color='blue')\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('Average Number of Required Epochs')\n",
        "plt.title('Average Number of Required Epochs per Model')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wp2bdgDVtJt1"
      },
      "outputs": [],
      "source": [
        "# Plot accuracies\n",
        "n_models = len(average_successful_train_accuracies)  # Number of models\n",
        "ind = np.arange(n_models)  # the x locations for the groups\n",
        "width = 0.35  # the width of the bars\n",
        "fig1, ax1 = plt.subplots()\n",
        "train_bars = ax1.bar(ind, average_successful_train_accuracies, width, label='Standard', color='b')\n",
        "# Add some text for labels, title, and custom x-axis tick labels, etc.\n",
        "ax1.set_xlabel('Models')\n",
        "ax1.set_ylabel('Accuracy')\n",
        "ax1.set_title('Standard Accuracy by Model')\n",
        "ax1.set_xticks(ind)\n",
        "ax1.set_xticklabels(model_names, rotation=45, ha=\"right\")\n",
        "def autolabel(bars, ax):\n",
        "    \"\"\"Attach a text label above each bar in *bars*, displaying its height.\"\"\"\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        ax.annotate('{}'.format(round(height, 4)),\n",
        "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "                    xytext=(0, 3),  # 3 points vertical offset\n",
        "                    textcoords=\"offset points\",\n",
        "                    ha='center', va='bottom')\n",
        "autolabel(train_bars, ax1)\n",
        "fig1.tight_layout()\n",
        "# Plot robust accuracies\n",
        "fig2, ax2 = plt.subplots()\n",
        "robust_bars = ax2.bar(ind, average_successful_robust_accuracies, width, label='Robust', color='r')\n",
        "# Add some text for labels, title, and custom x-axis tick labels, etc.\n",
        "ax2.set_xlabel('Models')\n",
        "ax2.set_ylabel('Accuracy')\n",
        "ax2.set_title('Robust Accuracy by Model')\n",
        "ax2.set_xticks(ind)\n",
        "ax2.set_xticklabels(model_names, rotation=45, ha=\"right\")\n",
        "autolabel(robust_bars, ax2)\n",
        "fig2.tight_layout()\n",
        "# Show both plots\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kigfcb-nKrwZ"
      },
      "outputs": [],
      "source": [
        "# Filter the robust accuracies to exclude failed runs\n",
        "average_epsilon_attacks = np.zeros([9, number_of_epsilons])\n",
        "for i in range(9):\n",
        "  for j in range(number_of_loops):\n",
        "    average_epsilon_attacks[i] = np.nanmean(marked_robust_accuracies[i,:,:], axis=0)\n",
        "plt.figure(figsize=(12, 8))\n",
        "# Plot each line with corresponding color\n",
        "for i, array in enumerate(average_epsilon_attacks):\n",
        "    plt.plot(epsilons, array, marker='.', color=colors[i], label=model_names[i])\n",
        "# Add labels and legend\n",
        "plt.xlabel('Epsilon')\n",
        "plt.ylabel('Robust Accuracy')\n",
        "plt.title('Robust Accuracies by Model and Epsilon')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "# Show plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xrokXMvITnyG"
      },
      "outputs": [],
      "source": [
        "# Robust accuracy per model with minina and maxima + variance\n",
        "maxima = np.zeros([9, number_of_epsilons])\n",
        "minima = np.zeros([9, number_of_epsilons])\n",
        "for i in range(9):\n",
        "  maxima[i] = np.nanmax(marked_robust_accuracies[i,:,:],axis=0)\n",
        "  minima[i] = np.nanmin(marked_robust_accuracies[i,:,:],axis=0)\n",
        "n_models = len(marked_robust_accuracies)\n",
        "var_accuracies = np.zeros((n_models, len(epsilons)))\n",
        "# Plot each line with error bars for mean, max, and min accuracies\n",
        "for i, array in enumerate(average_epsilon_attacks):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    var_accuracies[i] = np.nanstd(marked_robust_accuracies[i], axis=0) # save for other plot\n",
        "    plt.plot(epsilons, array, label='Mean', color=colors[i])\n",
        "    plt.plot(epsilons, maxima[i], label='Maximum', color=colors[i])\n",
        "    plt.plot(epsilons, minima[i], label='Minimum', color=colors[i])\n",
        "    # Add labels and legend\n",
        "    plt.xlabel('Epsilon')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Robust accuracies by epsilon - ' + model_names[i])\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "# Plot the variation on robust accuracies\n",
        "plt.figure(figsize=(12, 8))\n",
        "for i, array in enumerate(var_accuracies):\n",
        "    plt.plot(epsilons, array, marker='x', label=model_names[i], color=colors[i])\n",
        "# Add labels and legend\n",
        "plt.xlabel('Epsilon')\n",
        "plt.ylabel('Standard deviation of Robust Accuracy')\n",
        "plt.title('Standard deviation of Robust Accuracies by Model and Epsilon')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmIbf-ccodsp"
      },
      "outputs": [],
      "source": [
        "# Plot activation functions\n",
        "\n",
        "# Generate x values from -5 to 5\n",
        "x = torch.linspace(-10, 10, 1001)\n",
        "# Calculate y values for each function\n",
        "y_relu = ReLU(x)\n",
        "y_leaky_relu = LeakyReLU(x,0.01,1)\n",
        "y_softplus = Softplus(x)\n",
        "y_leaky_softplus = LeakySoftplus(x)\n",
        "y_semi_leaky_softplus = SemiLeakySoftplus(x)\n",
        "y_tanh = Tanh(x)\n",
        "y_leaky_tanh = LeakyTanh(x)\n",
        "y_sigmoid = Sigmoid(x)\n",
        "y_leaky_sigmoid = LeakySigmoid(x)\n",
        "\n",
        "# Plotting\n",
        "# ReLU\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(x, y_relu, color=colors[0])\n",
        "plt.title('ReLU')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('ReLU(x)')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "\n",
        "# Leaky ReLu\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(x, y_leaky_relu, color=colors[1])\n",
        "plt.title('Leaky ReLu')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('LeakyReLU(x)')\n",
        "plt.grid(True)\n",
        "\n",
        "# Softplus\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(x, y_softplus, color=colors[2])\n",
        "plt.title('Softplus')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('Softplus(x)')\n",
        "plt.grid(True)\n",
        "\n",
        "# Leaky Softplus\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(x, y_leaky_softplus, color=colors[3])\n",
        "plt.title('Leaky Softplus')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('LeakySoftplus(x)')\n",
        "plt.grid(True)\n",
        "\n",
        "# Semi-Leaky Softplus\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(x, y_semi_leaky_softplus, color=colors[4])\n",
        "plt.title('Semi-Leaky Softplus')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('SemiLeakySoftplus(x)')\n",
        "plt.grid(True)\n",
        "\n",
        "# Tanh\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(x, y_tanh, color=colors[5])\n",
        "plt.title('Tanh')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('Tanh(x)')\n",
        "plt.grid(True)\n",
        "\n",
        "# Leaky Tanh\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(x, y_leaky_tanh, color=colors[6])\n",
        "plt.title('Leaky Tanh')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('LeakyTanh(x)')\n",
        "plt.grid(True)\n",
        "\n",
        "# Sigmoid\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(x, y_sigmoid, color=colors[7])\n",
        "plt.title('Sigmoid')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('Sigmoid(x)')\n",
        "plt.grid(True)\n",
        "\n",
        "# Leaky Sigmoid\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(x, y_leaky_sigmoid, color=colors[8])\n",
        "plt.title('Leaky Sigmoid')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('LeakySigmoid(x)')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}